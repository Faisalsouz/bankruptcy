{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path for reading the Compustat lists\n",
    "path = 'D:\\\\studyproject\\\\bankruptcy\\\\data\\\\compustat\\\\' # for win decomment this line\n",
    "# path = '/Users/user/Documents/Bankruptcy/bankruptcy/data/compustat/' # for mac decomment this line\n",
    "\n",
    "# set the path for reading the csv files\n",
    "# --------------- for win ---------------\n",
    "path_b = 'convertedCSVfiles\\\\bankrupt\\\\'\n",
    "path_h = 'convertedCSVfiles\\\\healthy\\\\'\n",
    "# --------------- for mac ---------------\n",
    "# path_b = './convertedCSVfiles/bankrupt/'\n",
    "# path_h = './convertedCSVfiles/healthy/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Merging Bankrupt Companies Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the bankrupt list\n",
    "bankrupt = pd.read_csv(str(path + 'list_bankrupt.csv'), dtype=object)\n",
    "\n",
    "# remove the glitch column\n",
    "bankrupt = bankrupt.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "bankrupt.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. ISIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# work with ISIN codes converted from CUSIP\n",
    "# ----------------------------------------------------------------------\n",
    "# set the path\n",
    "\n",
    "# read the bankrupt companies CUSIP to ISIN convert-table csv file\n",
    "bankrupt_csp2isn = pd.read_csv(path_b + 'bankrupt_csp2isn.csv', dtype=object)\n",
    "bankrupt_csp2isn.rename(columns={'Unnamed: 0':'CUSIP'}, inplace=True)\n",
    "\n",
    "print(bankrupt_csp2isn.head(), '\\n\\n')\n",
    "\n",
    "# check the compatibility of CUSIP columns in two dataframe, before merging\n",
    "for i in range(len(bankrupt)):\n",
    "    if bankrupt.iloc[i][5] != bankrupt_csp2isn.iloc[i][0]:\n",
    "        print('WARNING: There is inconsistency at row:', i)\n",
    "        \n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# work with ISIN codes converted from Ticker\n",
    "# ----------------------------------------------------------------------\n",
    "# read the bankrupt companies Ticker to ISIN convert-table csv file\n",
    "bankrupt_tic2isn = pd.read_csv(path_b + 'bankrupt_tic2isn.csv', dtype=object)\n",
    "bankrupt_tic2isn.rename(columns={'Unnamed: 0':'Ticker'}, inplace=True)\n",
    "\n",
    "print(bankrupt_tic2isn.head())\n",
    "\n",
    "# check the compatibility of Ticker columns in two dataframe, before merging\n",
    "for i in range(len(bankrupt)):\n",
    "    if bankrupt.iloc[i][4] != bankrupt_tic2isn.iloc[i][0]:\n",
    "        print('WARNING: There is inconsistency at row:', i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach the ISIN columns to the bankrupt dataframe\n",
    "bankrupt['csp2ISIN'] = bankrupt_csp2isn['ISIN']\n",
    "bankrupt['tic2ISIN'] = bankrupt_tic2isn['ISIN']\n",
    "\n",
    "bankrupt.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# merge the two ISIN columns\n",
    "# ----------------------------------------------------------------------\n",
    "# add a single column for ISIN, and\n",
    "bankrupt['ISIN'] = ''\n",
    "# a column to indicate there was inconsistency in converting symbols\n",
    "bankrupt['ISINc'] = ''\n",
    "\n",
    "for index, row in bankrupt.iterrows():\n",
    "    # in case of conflicts\n",
    "    if row['csp2ISIN'] != row['tic2ISIN']:\n",
    "        \n",
    "        # in case csp2ISN is NAN\n",
    "        if row['csp2ISIN'] != row['csp2ISIN']:\n",
    "            # in case both are NAN values\n",
    "            if row['tic2ISIN'] != row['tic2ISIN']:\n",
    "                # enter NAN as the ISIN value\n",
    "                row['ISIN'] = row['csp2ISIN']\n",
    "                # but no real inconsistency\n",
    "                row['ISINc'] = 0\n",
    "                \n",
    "            # in case only csp2ISIN is NAN\n",
    "            else:\n",
    "                # fill ISIN with tic2ISIN\n",
    "                row['ISIN'] = row['tic2ISIN']\n",
    "                # and mark it as an inconsistency\n",
    "                row['ISINc'] = 1\n",
    "        \n",
    "        # in case csp2ISIN is non-NAN value\n",
    "        else:\n",
    "            # in case tic2ISIN is NAN\n",
    "            if row['tic2ISIN'] != row['tic2ISIN']:\n",
    "                # fill ISIN with csp2ISIN\n",
    "                row['ISIN'] = row['csp2ISIN']\n",
    "                # and mark it as an inconsistency\n",
    "                row['ISINc'] = 1\n",
    "            \n",
    "            # in case both are non-NAN values\n",
    "            else:\n",
    "                # fill ISIN with both\n",
    "                row['ISIN'] = str(row['csp2ISIN']) + ' - ' + str(row['tic2ISIN'])\n",
    "                # and mark it as a serious inconsistency\n",
    "                row['ISINc'] = 3\n",
    "            \n",
    "    # in case of consistency        \n",
    "    else:\n",
    "        # fill ISIN with the value\n",
    "        row['ISIN'] = row['csp2ISIN']\n",
    "        # and it's consistent\n",
    "        row['ISINc'] = 0\n",
    "\n",
    "        \n",
    "# check the number of inconsistency cases\n",
    "inconsistency = len(bankrupt) - bankrupt['ISINc'].value_counts()[0]\n",
    "print(inconsistency, 'case(s) of inconsistency!')\n",
    "# check for serious cases of inconsistency\n",
    "if 3 in bankrupt['ISINc'].value_counts().index:\n",
    "    print(bankrupt['ISINc'].value_counts()[3], 'are serious!')\n",
    "else:\n",
    "    print('But none is serious.')\n",
    "    \n",
    "# check the number of successful conversion to RIC\n",
    "print('\\nAnd now we have', bankrupt.count().ISIN, 'bankrupt company with ISIN code.')\n",
    "\n",
    "\n",
    "# remove the extra *ISIN columns\n",
    "bankrupt = bankrupt.drop(['csp2ISIN', 'tic2ISIN'], axis=1)\n",
    "\n",
    "bankrupt.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. RIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# work with RIC codes converted from CUSIP\n",
    "# ----------------------------------------------------------------------\n",
    "# read the bankrupt companies CUSIP to RIC convert-table csv file\n",
    "bankrupt_csp2ric = pd.read_csv(path_b + 'bankrupt_csp2ric.csv', dtype=object)\n",
    "bankrupt_csp2ric.rename(columns={'Unnamed: 0':'CUSIP'}, inplace=True)\n",
    "\n",
    "print(bankrupt_csp2ric.head(), '\\n\\n')\n",
    "\n",
    "# check the compatibility of CUSIP columns in two dataframe, before merging\n",
    "for i in range(len(bankrupt)):\n",
    "    if bankrupt.iloc[i][5] != bankrupt_csp2ric.iloc[i][0]:\n",
    "        print('WARNING: There is inconsistency at row:', i)\n",
    "        \n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# work with RIC codes converted from Ticker\n",
    "# ----------------------------------------------------------------------\n",
    "# read the bankrupt companies Ticker to ISIN convert-table csv file\n",
    "bankrupt_tic2ric = pd.read_csv(path_b + 'bankrupt_tic2ric.csv', dtype=object)\n",
    "bankrupt_tic2ric.rename(columns={'Unnamed: 0':'Ticker'}, inplace=True)\n",
    "\n",
    "print(bankrupt_tic2ric.head())\n",
    "\n",
    "# check the compatibility of Ticker columns in two dataframe, before merging\n",
    "for i in range(len(bankrupt)):\n",
    "    if bankrupt.iloc[i][4] != bankrupt_tic2ric.iloc[i][0]:\n",
    "        print('WARNING: There is inconsistency at row:', i)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach the RIC columns to the bankrupt dataframe\n",
    "bankrupt['csp2RIC'] = bankrupt_csp2ric['RIC']\n",
    "bankrupt['tic2RIC'] = bankrupt_tic2ric['RIC']\n",
    "\n",
    "bankrupt.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# merge the two RIC columns\n",
    "# ----------------------------------------------------------------------\n",
    "# add a single column for RIC, and\n",
    "bankrupt['RIC'] = ''\n",
    "# a column to indicate there was inconsistency in converting symbols\n",
    "bankrupt['RICc'] = ''\n",
    "\n",
    "\n",
    "for index, row in bankrupt.iterrows():\n",
    "    # in case of conflicts\n",
    "    if row['csp2RIC'] != row['tic2RIC']:\n",
    "        \n",
    "        # in case csp2RIC is NAN\n",
    "        if row['csp2RIC'] != row['csp2RIC']:\n",
    "            # in case both are NAN values\n",
    "            if row['tic2RIC'] != row['tic2RIC']:\n",
    "                # enter NAN as the RIC value\n",
    "                row['RIC'] = row['csp2RIC']\n",
    "                # but no real inconsistency\n",
    "                row['RICc'] = 0\n",
    "                \n",
    "            # in case only csp2RIC is NAN\n",
    "            else:\n",
    "                # fill RIC with tic2RIC\n",
    "                row['RIC'] = row['tic2RIC']\n",
    "                # and mark it as an inconsistency\n",
    "                row['RICc'] = 1\n",
    "        \n",
    "        # in case csp2RIC is non-NAN value\n",
    "        else:\n",
    "            # in case tic2RIC is NAN\n",
    "            if row['tic2RIC'] != row['tic2RIC']:\n",
    "                # fill RIC with csp2RIC\n",
    "                row['RIC'] = row['csp2RIC']\n",
    "                # and mark it as an inconsistency\n",
    "                row['RICc'] = 1\n",
    "            \n",
    "            # in case both are non-NAN values\n",
    "            else:\n",
    "                # fill RIC with both\n",
    "                row['RIC'] = str(row['csp2RIC']) + ' - ' + str(row['tic2RIC'])\n",
    "                # and mark it as a serious inconsistency\n",
    "                row['RICc'] = 3\n",
    "            \n",
    "    # in case of consistency        \n",
    "    else:\n",
    "        # fill RIC with the value\n",
    "        row['RIC'] = row['csp2RIC']\n",
    "        # and it's consistent\n",
    "        row['RICc'] = 0\n",
    "\n",
    "        \n",
    "# check the number of inconsistency cases\n",
    "inconsistency = len(bankrupt) - bankrupt['RICc'].value_counts()[0]\n",
    "print(inconsistency, 'case(s) of inconsistency!')\n",
    "# check for serious cases of inconsistency\n",
    "if 3 in bankrupt['RICc'].value_counts().index:\n",
    "    print(bankrupt['RICc'].value_counts()[3], 'are serious!')\n",
    "else:\n",
    "    print('But none is serious.')\n",
    "\n",
    "# check the number of successful conversion to RIC\n",
    "print('\\nAnd now we have', bankrupt.count().RIC, 'bankrupt company with RIC code.')\n",
    "\n",
    "\n",
    "# remove the extra *ISIN columns\n",
    "bankrupt = bankrupt.drop(['csp2RIC', 'tic2RIC'], axis=1)\n",
    "\n",
    "\n",
    "bankrupt.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Merging Healthy Companies Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the healthy list\n",
    "healthy = pd.read_csv(str(path + 'list_healthy.csv'), dtype=object)\n",
    "\n",
    "# remove the glitch column\n",
    "healthy = healthy.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "healthy.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. ISIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# read and merge ISIN codes converted from CUSIP\n",
    "# ----------------------------------------------------------------------\n",
    "# read the healthy companies CUSIP to ISIN conversion csv files\n",
    "healthy_csp2isn = [pd.read_csv(path_h + 'healthy_csp2isn{}.csv'.format(i+1), dtype=object) for i in range(6)]\n",
    "# merge them\n",
    "healthy_csp2isn = pd.concat([healthy_csp2isn[i] for i in range(6)])\n",
    "# clean the resulted dataframe\n",
    "healthy_csp2isn.rename(columns={'Unnamed: 0':'CUSIP', 'ISIN':'csp2ISIN'}, inplace=True)\n",
    "# and remove that extra uninformative column\n",
    "healthy_csp2isn = healthy_csp2isn.drop(['error'], axis=1)\n",
    "\n",
    "# check the dataframe\n",
    "print('\\nThe CUSIP-to-ISIN conversion dataframe:')\n",
    "print('\\n', healthy_csp2isn.head())\n",
    "\n",
    "# first-merge CUSIP-to-ISIN dataframe with the healthy list\n",
    "healthy = healthy.merge(healthy_csp2isn, how='left', on=['CUSIP']) \n",
    "\n",
    "print('\\n---------------------- First Merge Done! -----------------------------\\n')\n",
    "\n",
    "# the first merge results\n",
    "print('The merge result:\\n')\n",
    "print(healthy.head())\n",
    "\n",
    "print('\\n----------------------------------------------------------------------\\n')\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# read and merge ISIN codes converted from Ticker\n",
    "# ----------------------------------------------------------------------\n",
    "# read the healthy companies Ticker to ISIN conversion csv files\n",
    "healthy_tic2isn = [pd.read_csv(path_h + 'healthy_tic2isn{}.csv'.format(i+1), dtype=object) for i in range(6)]\n",
    "# merge them\n",
    "healthy_tic2isn = pd.concat([healthy_tic2isn[i] for i in range(6)])\n",
    "# clean the resulted dataframe\n",
    "healthy_tic2isn.rename(columns={'Unnamed: 0':'Ticker', 'ISIN':'tic2ISIN'}, inplace=True)\n",
    "# and remove that extra uninformative column\n",
    "healthy_tic2isn = healthy_tic2isn.drop(['error'], axis=1)\n",
    "\n",
    "# check the dataframe\n",
    "print('\\nThe Ticker-to-ISIN conversion dataframe:')\n",
    "print('\\n', healthy_tic2isn.head())\n",
    "\n",
    "# second merge Ticker-to-ISIN dataframe with the first-merged healthy list\n",
    "healthy = healthy.merge(healthy_tic2isn, on=['Ticker'], how='left')\n",
    "\n",
    "print('\\n--------------------- Second Merge Done! -----------------------------\\n')\n",
    "\n",
    "# the second merge results\n",
    "print('The merge result:')\n",
    "print('\\n\\n', healthy.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# merge the two ISIN columns\n",
    "# ----------------------------------------------------------------------\n",
    "# add a single column for ISIN, and\n",
    "healthy['ISIN'] = ''\n",
    "# a column to indicate there was inconsistency in converting symbols\n",
    "healthy['ISINc'] = ''\n",
    "\n",
    "for index, row in healthy.iterrows():\n",
    "    # in case of conflicts\n",
    "    if row['csp2ISIN'] != row['tic2ISIN']:\n",
    "        \n",
    "        # in case csp2ISN is NAN\n",
    "        if row['csp2ISIN'] != row['csp2ISIN']:\n",
    "            # in case both are NAN values\n",
    "            if row['tic2ISIN'] != row['tic2ISIN']:\n",
    "                # enter NAN as the ISIN value\n",
    "                row['ISIN'] = row['csp2ISIN']\n",
    "                # but no real inconsistency\n",
    "                row['ISINc'] = 0\n",
    "                \n",
    "            # in case only csp2ISIN is NAN\n",
    "            else:\n",
    "                # fill ISIN with tic2ISIN\n",
    "                row['ISIN'] = row['tic2ISIN']\n",
    "                # and mark it as an inconsistency\n",
    "                row['ISINc'] = 1\n",
    "        \n",
    "        # in case csp2ISIN is non-NAN value\n",
    "        else:\n",
    "            # in case tic2ISIN is NAN\n",
    "            if row['tic2ISIN'] != row['tic2ISIN']:\n",
    "                # fill ISIN with csp2ISIN\n",
    "                row['ISIN'] = row['csp2ISIN']\n",
    "                # and mark it as an inconsistency\n",
    "                row['ISINc'] = 1\n",
    "            \n",
    "            # in case both are non-NAN values\n",
    "            else:\n",
    "                # fill ISIN with both\n",
    "                row['ISIN'] = str(row['csp2ISIN']) + ' - ' + str(row['tic2ISIN'])\n",
    "                # and mark it as a serious inconsistency\n",
    "                row['ISINc'] = 3\n",
    "            \n",
    "    # in case of consistency        \n",
    "    else:\n",
    "        # fill ISIN with the value\n",
    "        row['ISIN'] = row['csp2ISIN']\n",
    "        # and it's consistent\n",
    "        row['ISINc'] = 0\n",
    "\n",
    "        \n",
    "# check the number of inconsistency cases\n",
    "inconsistency = len(healthy) - healthy['ISINc'].value_counts()[0]\n",
    "print(inconsistency, 'case(s) of inconsistency!')\n",
    "# check for serious cases of inconsistency\n",
    "if 3 in healthy['ISINc'].value_counts().index:\n",
    "    print(healthy['ISINc'].value_counts()[3], 'are serious!')\n",
    "else:\n",
    "    print('But none is serious.')\n",
    "    \n",
    "# check the number of successful conversion to ISIN\n",
    "print('\\nAnd now we have', len(healthy) - healthy['ISIN'].isna().sum(), 'bankrupt company with ISIN code.')\n",
    "\n",
    "\n",
    "# remove the extra *ISIN columns\n",
    "healthy = healthy.drop(['csp2ISIN', 'tic2ISIN'], axis=1)\n",
    "\n",
    "\n",
    "healthy.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. RIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# read and merge RIC codes converted from CUSIP\n",
    "# ----------------------------------------------------------------------\n",
    "# read the healthy companies CUSIP to RIC convert-table csv files\n",
    "healthy_csp2ric = [pd.read_csv(path_h + 'healthy_csp2ric{}.csv'.format(i+1), dtype=object) for i in range(6)]\n",
    "# merge them\n",
    "healthy_csp2ric = pd.concat([healthy_csp2ric[i] for i in range(6)])\n",
    "# clean the resulted dataframe\n",
    "healthy_csp2ric.rename(columns={'Unnamed: 0':'CUSIP', 'RIC':'csp2RIC'}, inplace=True)\n",
    "# and remove that extra uninformative column\n",
    "healthy_csp2ric = healthy_csp2ric.drop(['error'], axis=1)\n",
    "\n",
    "# check the dataframe\n",
    "print('\\nThe CUSIP-to-RIC conversion dataframe:')\n",
    "print('\\n', healthy_csp2ric.head())\n",
    "\n",
    "# first-merge CUSIP-to-RIC dataframe with the healthy list\n",
    "healthy = healthy.merge(healthy_csp2ric, how='left', on=['CUSIP']) \n",
    "\n",
    "print('\\n---------------------- First Merge Done! -----------------------------\\n')\n",
    "\n",
    "# the first merge results\n",
    "print('The merge result:\\n')\n",
    "print(healthy.head())\n",
    "\n",
    "print('\\n----------------------------------------------------------------------\\n')\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# read and merge RIC codes converted from Ticker\n",
    "# ----------------------------------------------------------------------\n",
    "# read the healthy companies Ticker to RIC conversion csv files\n",
    "healthy_tic2ric = [pd.read_csv(path_h + 'healthy_tic2ric{}.csv'.format(i+1), dtype=object) for i in range(6)]\n",
    "# merge them\n",
    "healthy_tic2ric = pd.concat([healthy_tic2ric[i] for i in range(6)])\n",
    "# clean the resulted dataframe\n",
    "healthy_tic2ric.rename(columns={'Unnamed: 0':'Ticker', 'RIC':'tic2RIC'}, inplace=True)\n",
    "# and remove that extra uninformative column\n",
    "healthy_tic2ric = healthy_tic2ric.drop(['error'], axis=1)\n",
    "\n",
    "# check the dataframe\n",
    "print('\\nThe Ticker-to-RIC conversion dataframe:')\n",
    "print('\\n', healthy_tic2ric.head())\n",
    "\n",
    "# second merge Ticker-to-RIC dataframe with the first-merged healthy list\n",
    "healthy = healthy.merge(healthy_tic2ric, on=['Ticker'], how='left')\n",
    "\n",
    "print('\\n--------------------- Second Merge Done! -----------------------------\\n')\n",
    "\n",
    "# the second merge results\n",
    "print('The merge result:')\n",
    "print('\\n\\n', healthy.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# merge the two RIC columns\n",
    "# ----------------------------------------------------------------------\n",
    "# add a single column for RIC, and\n",
    "healthy['RIC'] = ''\n",
    "# a column to indicate there was inconsistency in converting symbols\n",
    "healthy['RICc'] = ''\n",
    "\n",
    "for index, row in healthy.iterrows():\n",
    "    # in case of conflicts\n",
    "    if row['csp2RIC'] != row['tic2RIC']:\n",
    "        \n",
    "        # in case csp2RIC is NAN\n",
    "        if row['csp2RIC'] != row['csp2RIC']:\n",
    "            # in case both are NAN values\n",
    "            if row['tic2RIC'] != row['tic2RIC']:\n",
    "                # enter NAN as the ISIN value\n",
    "                row['RIC'] = row['csp2RIC']\n",
    "                # but no real inconsistency\n",
    "                row['RICc'] = 0\n",
    "                \n",
    "            # in case only csp2RIC is NAN\n",
    "            else:\n",
    "                # fill RIC with tic2RIC\n",
    "                row['RIC'] = row['tic2RIC']\n",
    "                # and mark it as an inconsistency\n",
    "                row['RICc'] = 1\n",
    "        \n",
    "        # in case csp2RIC is non-NAN value\n",
    "        else:\n",
    "            # in case tic2RIC is NAN\n",
    "            if row['tic2RIC'] != row['tic2RIC']:\n",
    "                # fill RIC with csp2RIC\n",
    "                row['RIC'] = row['csp2RIC']\n",
    "                # and mark it as an inconsistency\n",
    "                row['RICc'] = 1\n",
    "            \n",
    "            # in case both are non-NAN values\n",
    "            else:\n",
    "                # fill RIC with both\n",
    "                row['RIC'] = str(row['csp2RIC']) + ' - ' + str(row['tic2RIC'])\n",
    "                # and mark it as a serious inconsistency\n",
    "                row['RICc'] = 3\n",
    "            \n",
    "    # in case of consistency        \n",
    "    else:\n",
    "        # fill RIC with the value\n",
    "        row['RIC'] = row['csp2RIC']\n",
    "        # and it's consistent\n",
    "        row['RICc'] = 0\n",
    "\n",
    "        \n",
    "# check the number of inconsistency cases\n",
    "inconsistency = len(healthy) - healthy['RICc'].value_counts()[0]\n",
    "print(inconsistency, 'case(s) of inconsistency!')\n",
    "# check for serious cases of inconsistency\n",
    "if 3 in healthy['RICc'].value_counts().index:\n",
    "    print(healthy['RICc'].value_counts()[3], 'are serious!')\n",
    "else:\n",
    "    print('But none is serious.')\n",
    "    \n",
    "# check the number of successful conversion to RIC\n",
    "print('\\nAnd now we have', len(healthy) - healthy['RIC'].isna().sum(), 'bankrupt company with RIC code.')\n",
    "\n",
    "\n",
    "# remove the extra *RIC columns\n",
    "healthy = healthy.drop(['csp2RIC', 'tic2RIC'], axis=1)\n",
    "\n",
    "\n",
    "healthy.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the final csv files of bankrupt and healthy companies\n",
    "bankrupt.to_csv('final_bankrupt_list.csv')\n",
    "healthy.to_csv('final_healthy_list.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract and locally-save 4 lists of RICs and ISINs for bankrupt and healthy companies\n",
    "\n",
    "# create a folder to save the list-pickles\n",
    "if not os.path.exists('Lists'):\n",
    "    os.makedirs('Lists')\n",
    "\n",
    "# ISIN list for bankrupt companies\n",
    "bankrupt_ISIN = bankrupt.ISIN[bankrupt['ISINc'] != 3].dropna().to_list()\n",
    "# handle serious conflict cases which include more than one code\n",
    "for index, row in bankrupt.iterrows():\n",
    "    if row['ISINc'] == 3:\n",
    "        bankrupt_ISIN.append(row['ISIN'][:row['ISIN'].find(' - ')])\n",
    "        bankrupt_ISIN.append(row['ISIN'][row['ISIN'].find(' - ') + 3:])\n",
    "# and save the list\n",
    "with open('Lists/bankrupt_ISIN.txt', 'wb') as f:\n",
    "    pickle.dump(bankrupt_ISIN, f)\n",
    "    \n",
    "\n",
    "# create RIC list for bankrupt companies\n",
    "bankrupt_RIC = bankrupt.RIC[bankrupt['RICc'] != 3].dropna().to_list()\n",
    "# handle serious conflict cases which include more than one code\n",
    "for index, row in bankrupt.iterrows():\n",
    "    if row['RICc'] == 3:\n",
    "        bankrupt_RIC.append(row['RIC'][:row['RIC'].find(' - ')])\n",
    "        bankrupt_RIC.append(row['RIC'][row['RIC'].find(' - ') + 3:])\n",
    "# and save the list\n",
    "with open('Lists/bankrupt_RIC.txt', 'wb') as f:\n",
    "    pickle.dump(bankrupt_RIC, f)\n",
    "    \n",
    "\n",
    "# ISIN list for healthy companies\n",
    "healthy_ISIN = healthy.ISIN[healthy['ISINc'] != 3].dropna().to_list()\n",
    "# handle serious conflict cases which include more than one code\n",
    "for index, row in healthy.iterrows():\n",
    "    if row['ISINc'] == 3:\n",
    "        healthy_ISIN.append(row['ISIN'][:row['ISIN'].find(' - ')])\n",
    "        healthy_ISIN.append(row['ISIN'][row['ISIN'].find(' - ') + 3:])\n",
    "# and save the list\n",
    "with open('Lists/healthy_ISIN.txt', 'wb') as f:\n",
    "    pickle.dump(healthy_ISIN, f)\n",
    "    \n",
    "    \n",
    "# RIC list for healthy companies\n",
    "healthy_RIC = healthy.RIC[healthy['RICc'] != 3].dropna().to_list()\n",
    "# handle serious conflict cases which include more than one code\n",
    "for index, row in healthy.iterrows():\n",
    "    if row['RICc'] == 3:\n",
    "        healthy_RIC.append(row['RIC'][:row['RIC'].find(' - ')])\n",
    "        healthy_RIC.append(row['RIC'][row['RIC'].find(' - ') + 3:])\n",
    "# and save the list\n",
    "with open('Lists/healthy_RIC.txt', 'wb') as f:\n",
    "    pickle.dump(healthy_RIC, f)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
