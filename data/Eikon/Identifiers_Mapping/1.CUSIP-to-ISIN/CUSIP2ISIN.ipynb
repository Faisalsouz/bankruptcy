{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Identifier                       Company Data Deletion Date Deletion Reason  \\\n",
      "0     001367  Amber Resources Company of C         08/31/2012             2.0   \n",
      "1     002033         Fairchild Corp. (The)         11/01/2011             2.0   \n",
      "2     004049     Constar International Inc         06/01/2011             2.0   \n",
      "3     004352  Energy Conversion Devices In         09/04/2012             2.0   \n",
      "4     004768    Fleetwood Enterprises Inc.         08/23/2010             2.0   \n",
      "\n",
      "  Ticker      CUSIP         CIK          ISIN ISINc           RIC RICc  \n",
      "0  3AMBE  023184203  0000276750  US0231842032     1           NaN    0  \n",
      "1  FCHDQ  303698104  0000009779  US3036981047     0  FCHDQ.PK^K11    1  \n",
      "2  CNSTQ  21036U206  0000029806  US21036U2069     1           NaN    0  \n",
      "3  ENERQ  292659109  0000032878  US2926591098     0  ENERQ.PK^I12    1  \n",
      "4  FLTWQ  339099103  0000314132  US3390991038     0  FLTWQ.PK^H10    1  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identifier</th>\n",
       "      <th>Company</th>\n",
       "      <th>Data Deletion Date</th>\n",
       "      <th>Deletion Reason</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>CUSIP</th>\n",
       "      <th>CIK</th>\n",
       "      <th>ISIN</th>\n",
       "      <th>ISINc</th>\n",
       "      <th>RIC</th>\n",
       "      <th>RICc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001004</td>\n",
       "      <td>AAR Corp</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AIR</td>\n",
       "      <td>000361105</td>\n",
       "      <td>0000001750</td>\n",
       "      <td>US0003611052</td>\n",
       "      <td>0</td>\n",
       "      <td>AIR</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001013</td>\n",
       "      <td>ADC Telecommunications Inc.</td>\n",
       "      <td>12/10/2010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ADCT</td>\n",
       "      <td>000886309</td>\n",
       "      <td>0000061478</td>\n",
       "      <td>US0008863096</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001021</td>\n",
       "      <td>AFP Imaging Corp</td>\n",
       "      <td>09/15/2014</td>\n",
       "      <td>7.0</td>\n",
       "      <td>IWKS</td>\n",
       "      <td>001058205</td>\n",
       "      <td>0000319126</td>\n",
       "      <td>US0010582056</td>\n",
       "      <td>0</td>\n",
       "      <td>IWKS.PK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001034</td>\n",
       "      <td>Alpharma Inc.</td>\n",
       "      <td>12/31/2008</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALO.2</td>\n",
       "      <td>020813101</td>\n",
       "      <td>0000730469</td>\n",
       "      <td>US0208131013</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001045</td>\n",
       "      <td>American Airlines Group Inc</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAL</td>\n",
       "      <td>02376R102</td>\n",
       "      <td>0000006201</td>\n",
       "      <td>US02376R1023</td>\n",
       "      <td>0</td>\n",
       "      <td>AAL.O - AAL.Z</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Identifier                      Company Data Deletion Date Deletion Reason  \\\n",
       "0     001004                     AAR Corp                  .             NaN   \n",
       "1     001013  ADC Telecommunications Inc.         12/10/2010             1.0   \n",
       "2     001021             AFP Imaging Corp         09/15/2014             7.0   \n",
       "3     001034                Alpharma Inc.         12/31/2008             1.0   \n",
       "4     001045  American Airlines Group Inc                  .             NaN   \n",
       "\n",
       "  Ticker      CUSIP         CIK          ISIN ISINc            RIC RICc  \n",
       "0    AIR  000361105  0000001750  US0003611052     0            AIR    0  \n",
       "1   ADCT  000886309  0000061478  US0008863096     1            NaN    0  \n",
       "2   IWKS  001058205  0000319126  US0010582056     0        IWKS.PK    1  \n",
       "3  ALO.2  020813101  0000730469  US0208131013     1            NaN    0  \n",
       "4    AAL  02376R102  0000006201  US02376R1023     0  AAL.O - AAL.Z    3  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the path for reading the Compustat lists\n",
    "path = 'D:\\\\studyproject\\\\bankruptcy\\\\data\\\\Eikon\\\\Identifiers_Mapping\\\\' + \\\n",
    "           '0.Ticker_CUSIP-to-ISIN_RIC\\\\' # for win decomment this line\n",
    "# path = '/Users/user/Documents/Bankruptcy/bankruptcy/data/Eikon/ \\\\\n",
    "#        Identifiers_Mapping/0.Ticker_CUSIP-to-ISIN_RIC/' # for mac decomment this line\n",
    "\n",
    "# read the lists from the previous conversion\n",
    "bankrupt = pd.read_csv(path + '0.bankrupt_list.csv', dtype=object, index_col=[0])\n",
    "healthy = pd.read_csv(path + '0.healthy_list.csv', dtype=object, index_col=[0])\n",
    "\n",
    "print(bankrupt.head())\n",
    "healthy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the Currency Column from the Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later on we will need the currency in which the company's\n",
    "# shares being traded, as an acceptable approximation of its\n",
    "# headquarter to determine the first 2 letters of the ISIN code\n",
    "\n",
    "# set the path\n",
    "path = 'D:\\\\studyproject\\\\bankruptcy\\\\data\\\\Compustat\\\\' # for win\n",
    "\n",
    "identifier = pd.read_fwf(path + 'chunk_1.rtf', dtype=object)\n",
    "currency = pd.read_fwf(path + 'chunk_2.rtf', dtype=object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01 Communique Laboratory Inc</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0373849 B C Ltd</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-800 Contacts Inc</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-800-FLOWERS.COM Inc</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111 Inc</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Company Country\n",
       "0  01 Communique Laboratory Inc      CA\n",
       "1               0373849 B C Ltd      CA\n",
       "2            1-800 Contacts Inc      US\n",
       "3         1-800-FLOWERS.COM Inc      US\n",
       "4                       111 Inc      US"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a dataframe out of the company names\n",
    "country = identifier[['conml']].copy()\n",
    "country.rename(columns={'conml':'Company'}, inplace=True) # rename the column\n",
    "\n",
    "# and the currency column\n",
    "country['Country'] = currency['curcd'].values\n",
    "\n",
    "# group them by company names\n",
    "country = country.groupby(['Company']).max().reset_index()\n",
    "\n",
    "# change the currency to countries 2-letter abbreviation\n",
    "country.Country.replace(['USD', 'CAD'], ['US', 'CA'], inplace=True)\n",
    "\n",
    "country.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the column currency to the two dataframes\n",
    "bankrupt = bankrupt.merge(country, how='inner', on=['Company'])\n",
    "healthy = healthy.merge(country, how='inner', on=['Company'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the Conversion Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement the CUSIP to ISIN formula\n",
    "\n",
    "def c2i(CUSIP, country_code):\n",
    "    '''\n",
    "    This function takes CUSIP and the country code, and\n",
    "    returns the ISIN.\n",
    "    '''\n",
    "    if country_code == 'US':\n",
    "        ISIN2B = '3028'+ CUSIP\n",
    "    else:\n",
    "        ISIN2B = '1210' + CUSIP\n",
    "    \n",
    "\n",
    "    ISIN = []\n",
    "    for ch in ISIN2B:\n",
    "        try:\n",
    "            ISIN.append(int(ch))\n",
    "        except:\n",
    "            ISIN.append((ord(ch) - 55) // 10)\n",
    "            ISIN.append((ord(ch) - 55) % 10)\n",
    "        \n",
    "        \n",
    "    counter = -1\n",
    "    list_a = []\n",
    "    list_B = []\n",
    "    while counter >= -len(ISIN):\n",
    "        list_a.append(ISIN[counter])\n",
    "        try:        \n",
    "            list_B.append(ISIN[counter-1])\n",
    "        except:\n",
    "            pass\n",
    "        counter -= 2\n",
    "        \n",
    "    list_a = [2 * x for x in list_a]\n",
    "    \n",
    "    list_A = []\n",
    "    for i in list_a:\n",
    "        if i <= 9:\n",
    "            list_A.append(i)\n",
    "        else:\n",
    "            list_A.append(i // 10)\n",
    "            list_A.append(i % 10)\n",
    "    \n",
    "    final_digit = (10 - ((sum(list_A) + sum(list_B)) % 10)) % 10\n",
    "    ISIN = country_code + CUSIP + str(final_digit)\n",
    "    \n",
    "         \n",
    "    return ISIN\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the Conversion Function to a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert lists CUSIPs to ISINs\n",
    "def createISIN(df):\n",
    "    '''\n",
    "    this functions takes bankrupt and healthy dataframes,\n",
    "    use the CUSIP column and creates corresponding ISINs,\n",
    "    and compare the consistency with the existing ISINS\n",
    "    '''\n",
    "    # add an empty column for CUSIP-converted ISIN\n",
    "    df.insert(9, 'cusipISIN', '')\n",
    "\n",
    "    # iterate over dataframe rows\n",
    "    for index, row in df.iterrows():\n",
    "        # if CUSIP or Country not available return NAN\n",
    "        if (row['CUSIP'] != row['CUSIP']) or (row['Country'] != row['Country']):\n",
    "            row['cusipISIN'] = np.nan\n",
    "        # else convert CUSIP to ISIN\n",
    "        else:\n",
    "            row['cusipISIN'] = c2i(row['CUSIP'], row['Country'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkConsistency(df):\n",
    "    '''\n",
    "    The function takes the bankrupt and healthy dataframes,\n",
    "    and check the consistency of ISIN and cusipISIN columns.\n",
    "    '''\n",
    "    # iterate over rows\n",
    "    for index, row in df.iterrows():\n",
    "        # if cusipISIN is not available, pass\n",
    "        if row['cusipISIN'] != row['cusipISIN']:\n",
    "            pass\n",
    "        else:\n",
    "            # there are 4 different cases possible:\n",
    "\n",
    "            # ISINc = 0, so no inconsistency:\n",
    "            if row['ISINc'] == '0':\n",
    "                # 1. but no ISIN code either\n",
    "                if row['ISIN'] != row['ISIN']:\n",
    "                    # replace ISIN's NAN value with cusipISIN\n",
    "                    row['ISIN'] = row['cusipISIN']\n",
    "                    # but mention the inconsistency\n",
    "                    row['ISINc'] = '1'\n",
    "                # 2. and a ISIN code available\n",
    "                else:\n",
    "                    # check wether the two ISIN codes are the same\n",
    "                    # if they are, everything's cool and we don't need\n",
    "                    # to do anything, esle\n",
    "                    if not (row['ISIN'] == row['cusipISIN']):\n",
    "                        # we add the new ISIN to the previous one\n",
    "                        row['ISIN'] = row['ISIN'] + ' - ' + row['cusipISIN']\n",
    "                        # and mention the inconsistency\n",
    "                        # but since now two out of three conversaions had\n",
    "                        # consistent result, the value of ISINc would be .5\n",
    "                        row['ISINc'] = '.5'\n",
    "\n",
    "            # 3. case in which we have an ISIN code but it's only\n",
    "            # from one of the two tries of creating the code, and\n",
    "            # the other one produced no results\n",
    "            elif row['ISINc'] == '1':\n",
    "                # if the code is consistent with the newly created ISIN\n",
    "                if row['ISIN'] == row['cusipISIN']:\n",
    "                    # assume consistency\n",
    "                    row['ISINc'] = '0'\n",
    "                # and if not\n",
    "                else:\n",
    "                    # add the new code to the ISIN column\n",
    "                    row['ISIN'] = row['ISIN'] + ' - ' + row['cusipISIN']\n",
    "                    # and increase the value of inconsistency\n",
    "                    # because now we have three different results \n",
    "                    row['ISINc'] = '3'\n",
    "\n",
    "            # 4. serious inconsistency case, in which we have already\n",
    "            # two differen ISIN codes\n",
    "            else:\n",
    "                # first break the code into its two parts\n",
    "                ISIN1 = row['ISIN'][:row['ISIN'].find(' - ')]\n",
    "                ISIN2 = row['ISIN'][row['ISIN'].find(' - ') + 3:]\n",
    "\n",
    "                # compare them against the new code, if one is the same\n",
    "                # with the new code, replace the ISIN with that code and\n",
    "                # reduce the inconsistency value to 1.\n",
    "                if ISIN1 == row['cusipISIN']:\n",
    "                    row['ISIN'] = ISIN1\n",
    "                    row['ISINc'] = '1'\n",
    "                elif ISIN2 == row['cusipISIN']:\n",
    "                    row['ISIN'] = ISIN2\n",
    "                    row['ISINc'] = '1'\n",
    "                # else we have three different codes and it hits a\n",
    "                # new level of inconsistency, so add the new code and\n",
    "                # increase the inconsistency value to 4\n",
    "                else:\n",
    "                    row['ISIN'] += ' - ' + row['cusipISIN']\n",
    "                    row['ISINc'] = '4'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the Two Functions to the Two Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inconsistency status of the bankrupt dataframe:\n",
      "0    93\n",
      "1    19\n",
      "Name: ISINc, dtype: int64\n",
      "\n",
      "Inconsistency status of the healthy dataframe:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    12778\n",
       "1     8149\n",
       "3      213\n",
       "Name: ISINc, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first check the inconsistency status of the dataframes\n",
    "print('Inconsistency status of the bankrupt dataframe:')\n",
    "print(bankrupt.ISINc.value_counts())\n",
    "print()\n",
    "print('Inconsistency status of the healthy dataframe:')\n",
    "healthy.ISINc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert CUSIPs to ISINs\n",
    "createISIN(bankrupt)\n",
    "createISIN(healthy)\n",
    "# add check the new ISIN with the previous ones\n",
    "checkConsistency(bankrupt)\n",
    "checkConsistency(healthy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inconsistency status of the bankrupt dataframe:\n",
      "0     104\n",
      "3       4\n",
      ".5      3\n",
      "1       1\n",
      "Name: ISINc, dtype: int64\n",
      "\n",
      "Inconsistency status of the healthy dataframe:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     17889\n",
       "1      1599\n",
       "3       871\n",
       ".5      761\n",
       "4        20\n",
       "Name: ISINc, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the inconsistency status after using the second conversion technique\n",
    "print('Inconsistency status of the bankrupt dataframe:')\n",
    "print(bankrupt.ISINc.value_counts())\n",
    "print()\n",
    "print('Inconsistency status of the healthy dataframe:')\n",
    "healthy.ISINc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the extra columns\n",
    "bankrupt = bankrupt.drop(['cusipISIN'], axis=1)\n",
    "healthy = healthy.drop(['cusipISIN'], axis=1)\n",
    "\n",
    "# and save the results as csv files\n",
    "bankrupt.to_csv('1.bankrupt_list.csv', index=False)\n",
    "healthy.to_csv('1.heathy_list.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract ISIN and RIC Lists \n",
    "#### For the Next Round of Conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract and locally-save 4 lists of RICs and ISINs for bankrupt and healthy companies\n",
    "\n",
    "# create a folder to save the list-pickles\n",
    "if not os.path.exists('Lists'):\n",
    "    os.makedirs('Lists')\n",
    "\n",
    "# ISIN list for bankrupt companies\n",
    "bankrupt_ISIN = bankrupt.ISIN[bankrupt['ISINc'] != 3].dropna().to_list()\n",
    "# handle serious conflict cases which include more than one code\n",
    "for index, row in bankrupt.iterrows():\n",
    "    if row['ISINc'] == 3:\n",
    "        bankrupt_ISIN.append(row['ISIN'][:row['ISIN'].find(' - ')])\n",
    "        bankrupt_ISIN.append(row['ISIN'][row['ISIN'].find(' - ') + 3:])\n",
    "# and save the list\n",
    "with open('Lists/bankrupt_ISIN.txt', 'wb') as f:\n",
    "    pickle.dump(bankrupt_ISIN, f)\n",
    "    \n",
    "\n",
    "# create RIC list for bankrupt companies\n",
    "bankrupt_RIC = bankrupt.RIC[bankrupt['RICc'] != 3].dropna().to_list()\n",
    "# handle serious conflict cases which include more than one code\n",
    "for index, row in bankrupt.iterrows():\n",
    "    if row['RICc'] == 3:\n",
    "        bankrupt_RIC.append(row['RIC'][:row['RIC'].find(' - ')])\n",
    "        bankrupt_RIC.append(row['RIC'][row['RIC'].find(' - ') + 3:])\n",
    "# and save the list\n",
    "with open('Lists/bankrupt_RIC.txt', 'wb') as f:\n",
    "    pickle.dump(bankrupt_RIC, f)\n",
    "    \n",
    "\n",
    "# ISIN list for healthy companies\n",
    "healthy_ISIN = healthy.ISIN[healthy['ISINc'] != 3].dropna().to_list()\n",
    "# handle serious conflict cases which include more than one code\n",
    "for index, row in healthy.iterrows():\n",
    "    if row['ISINc'] == 3:\n",
    "        healthy_ISIN.append(row['ISIN'][:row['ISIN'].find(' - ')])\n",
    "        healthy_ISIN.append(row['ISIN'][row['ISIN'].find(' - ') + 3:])\n",
    "# and save the list\n",
    "with open('Lists/healthy_ISIN.txt', 'wb') as f:\n",
    "    pickle.dump(healthy_ISIN, f)\n",
    "    \n",
    "    \n",
    "# RIC list for healthy companies\n",
    "healthy_RIC = healthy.RIC[healthy['RICc'] != 3].dropna().to_list()\n",
    "# handle serious conflict cases which include more than one code\n",
    "for index, row in healthy.iterrows():\n",
    "    if row['RICc'] == 3:\n",
    "        healthy_RIC.append(row['RIC'][:row['RIC'].find(' - ')])\n",
    "        healthy_RIC.append(row['RIC'][row['RIC'].find(' - ') + 3:])\n",
    "# and save the list\n",
    "with open('Lists/healthy_RIC.txt', 'wb') as f:\n",
    "    pickle.dump(healthy_RIC, f)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
