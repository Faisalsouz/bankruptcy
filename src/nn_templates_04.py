# -*- coding: utf-8 -*-
"""NN_Templates_04.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hQAChgeKF8hiDiTddTjLenLe3wQ_Vtvh

### Imports
"""

# Commented out IPython magic to ensure Python compatibility.
# TODO: Update for tf 2.0
# %tensorflow_version 1.x
import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
from keras.models import Sequential
from sklearn.metrics import confusion_matrix
from imblearn.over_sampling import ADASYN
from keras.layers import *
from keras.optimizers import Adam
from keras.preprocessing.sequence import TimeseriesGenerator

"""### Global Variables"""

# The batch size by which the training data is fed into the network.
BATCH_TRAINING = 2

# The function used to evaluate performace of the model and tune the parameters.
LOSS_FUNCTION = tf.keras.losses.BinaryCrossentropy()

# The function by which your models parameters are adjusted to seek a local minimum.
# OPTIMIZER = adjusted within the network functions

# The rate at which the optimizer seeks the local minimum.
LEARNING_RATE = 1

# The number of iterations for which the model is trained.
EPOCHS = 15

"""### Load the Dataset"""

# Import dataset from relevant source(s).
# TODO: Load full dataset, including embedding features.
bankrupt = 'https://raw.githubusercontent.com/shrnkm/bankruptcy/master/data/Eikon/small_test_sets/data_test_bankrupt.csv?token=AMBTQIEDX3Y6THOUJCBWE5C57D2BI'
healthy = 'https://raw.githubusercontent.com/shrnkm/bankruptcy/master/data/Eikon/small_test_sets/data_test_healthy.csv?token=AMBTQIDFPLUT2BGKOBNM2GK57D2EK'
df_mixed = pd.concat([pd.read_csv(bankrupt), pd.read_csv(healthy)])
np.random.seed(0)

# Normalize the dataset per Cora and Fatimah.
data = np.array(df_mixed.drop(['Instrument', 'Bankrupt'], axis=1).values)
labels = np.array(df_mixed['Bankrupt'])
data_res, labels_res = ADASYN(n_neighbors = 3).fit_sample(data, labels)

# # Split data based on years (80% of all years for training, 20% for testing).
split = 20 * 0.8
print("\nSplit after year {}".format(split))
train_data = []
train_labels = []
test_data = []
test_labels = []

idx = 0
for i in range(len(data_res)):
  if (idx <= split):
    train_data.append(data_res[i])
    train_labels.append(labels_res[i])
  else:
    test_data.append(data_res[i])
    test_labels.append(labels_res[i])
    if idx == split + 3:
      idx = 0
      continue

  idx += 1

# Drop irrelevant columns (years, instrument).
train_data = np.delete(train_data, 0, axis=1)
train_data = np.delete(train_data, -2, axis=1)

test_data = np.delete(test_data, 0, axis=1)
test_data = np.delete(test_data, -2, axis=1)
print("Length train data: {}, Length test data: {}".format(len(train_data), len(test_data)))

"""### Investigate the Dataset"""

# Print relevant information about the dataset(s) structure.
print("Number of training instruments: {}\nNumber of test instruments:{}".format(len(train_data), len(test_data)))
print("Shape of one instrument datapoint: {}".format(train_data[0].shape))

"""### Visualize the Dataset"""

# Visualize specific examples from the dataset to gain understanding of what each datapoint is composed.
print("Example instrument:\n\n{}".format(df_mixed.loc[0]))

"""### Build the TensorFlow Dataset"""

# Network variables.
num_features = train_data[0].shape[0]
num_inputs = int(split)

# Initialize the time-series generators.
train_generator = TimeseriesGenerator(train_data, train_labels, length=num_inputs, batch_size=BATCH_TRAINING, stride=num_inputs+1, shuffle=True)
test_generator = TimeseriesGenerator(test_data, test_labels, length=num_inputs)

# Visualize the newly created generator.
print('Number of samples: {}'.format(len(train_generator)))
print('Number of samples in first input pass: {}'.format(len(train_generator[0])))

# Inspect the generator.
print("Length of test generator: {}".format(len(test_generator.data)))

"""### Build the Model(s)"""

# Instantiate functions for each desired network architecture.

# Standard NN based on Mai et al.
def NN_Standard(input_shape):
    print('Shape: ', input_shape)
    model = Sequential()
    model.add(Dense(4, input_shape=input_shape))
    model.add(Flatten())
    model.add(Dense(1, activation='sigmoid'))
    model.compile(optimizer='adam',
                  loss=LOSS_FUNCTION,
                  # TODO: ROC Score
                  metrics=['accuracy'])
    
    model.summary()
    history = model.fit_generator(train_generator, epochs=EPOCHS)
    score, acc = model.evaluate(test_generator)

    return (model, history, acc)


# A deep NN.
def NN_Deep(input_shape):
    print('Shape: ', input_shape)
    model = Sequential()
    model.add(Dense(16, input_shape=input_shape))
    model.add(Dense(16, input_shape=input_shape))
    model.add(Dense(16, input_shape=input_shape))
    model.add(Dense(16, input_shape=input_shape))
    model.add(Flatten())
    model.add(Dense(1, activation='sigmoid'))
    model.compile(optimizer='adam',
                  loss=LOSS_FUNCTION,
                  # TODO: ROC Score
                  metrics=['accuracy'])
    
    model.summary()
    history = model.fit_generator(train_generator, epochs=EPOCHS)
    score, acc = model.evaluate(test_generator)

    return (model, history, acc)


# A wide NN.
def NN_Wide(input_shape):
    print('Shape: ', input_shape)
    model = Sequential()
    model.add(Dense(22, input_shape=input_shape))
    model.add(Flatten())
    model.add(Dense(1, activation='sigmoid'))
    model.compile(optimizer='adam',
                  loss=LOSS_FUNCTION,
                  # TODO: ROC Score
                  metrics=['accuracy'])
    
    model.summary()
    history = model.fit_generator(train_generator, epochs=EPOCHS)
    score, acc = model.evaluate(test_generator)

    return (model, history, acc)


# LTSM
def NN_LSTM(input_shape):
    print('Shape: ', input_shape)
    model = Sequential()
    model.add(LSTM(16, input_shape=input_shape, return_sequences=True))
    model.add(LSTM(16, input_shape=input_shape, return_sequences=True))
    model.add(Flatten())
    model.add(Dense(1, activation='sigmoid'))

    model.compile(optimizer='adam',
                  loss=LOSS_FUNCTION,
                  metrics=['accuracy'])
    
    model.summary()

    config = tf.ConfigProto(
      device_count={'GPU': 1},
      intra_op_parallelism_threads=1,
      allow_soft_placement=True
      )
    config.gpu_options.allow_growth = True
    config.gpu_options.per_process_gpu_memory_fraction = 0.6
    session = tf.Session(config=config)
    with session.as_default():
        with session.graph.as_default():
          history = model.fit_generator(train_generator, epochs=EPOCHS)
          score, acc = model.evaluate(test_generator)

    return (model, history, acc)


# CRNN
def NN_CRNN(input_shape):
    model = Sequential()
    model.add(Conv1D(16, 3, input_shape=input_shape))
    model.add(LSTM(16))
    # model.add(Flatten())
    model.add(Dense(1, activation='sigmoid'))

    model.compile(optimizer='adam',
                  loss=LOSS_FUNCTION,
                  metrics=['accuracy'])

    model.summary()
    config = tf.ConfigProto(
      device_count={'GPU': 1},
      intra_op_parallelism_threads=1,
      allow_soft_placement=True
      )
    config.gpu_options.allow_growth = True
    config.gpu_options.per_process_gpu_memory_fraction = 0.6
    session = tf.Session(config=config)
    with session.as_default():
        with session.graph.as_default():
          history = model.fit_generator(train_generator, epochs=EPOCHS)
          score, acc = model.evaluate(test_generator)

    return (model, history, acc)

"""### Structure the Data"""

# Instantiate a data object to store the values for visualization of the different models' performance.
class Model:
  def __init__(self, tpl, name):
    self.name = name
    self.model = tpl[0]
    self.history = tpl[1]
    self.acc = tpl[2]

"""### Train the models."""

# Clear the session.
tf.keras.backend.clear_session()

# Initialize, train, and evaluate the selected models.
nn_standard = Model(NN_Standard((num_inputs, num_features)), 'Standard Network')
nn_deep = Model(NN_Deep((num_inputs, num_features)), 'Deep Network')
nn_wide = Model(NN_Wide((num_inputs, num_features)), 'Wide Network')
nn_lstm = Model(NN_LSTM((num_inputs,num_features)), 'LSTM Network')
nn_crnn = Model(NN_CRNN((num_inputs,num_features)), 'CRNN Network')

models = [nn_standard, nn_deep, nn_wide, nn_lstm, nn_crnn]

"""### Visualize the Training Process"""

# Visualize evaluation measures for training data. 
np.random.seed(19680801)
fig, axs = plt.subplots(len(models), 2, figsize=(25, 30), facecolor='w', edgecolor='k')
fig.subplots_adjust(hspace = .5, wspace=.1)
for i in range(len(models)):
    axs[i, 0].plot(models[i].history.history['loss'])
    axs[i, 0].set_title('Training Loss: {}'.format(models[i].name))
    axs[i, 0].set_ylabel('Loss')
    axs[i, 0].set_xlabel('Epoch')
    axs[i, 1].plot(models[i].history.history['acc'], 'tab:red')
    axs[i, 1].set_title('Training Accuracy: {}'.format(models[i].name))
    axs[i, 1].set_ylabel('Accuracy')
    axs[i, 1].set_xlabel('Epoch')

"""### Evaluate Models on Test Data"""

# Evaluate models on test dataset.
for i in range(len(models)):
  print('Accuracy on test dataset ({model}): {acc}'.format(model=models[i].name, acc=models[i].acc))

"""### Additional Tasks"""

# TODO: Visualize test data accuracy in the same plot as the training data.
# TODO: Plot precision and ROC.
# TODO: Resolve confusion matrix for assessing test data results.
# TODO: Make sure benchmarks and network models are evaluated on same metrics.
# TODO: Test different network architectures and layer types. Compare results.
# TODO: Test different optimizers.

"""### Optimization"""

# Batch normalization.
# Adjust the learning rate.
# Glorot initialization.
# Dropout.
# Add a plot of the test learning and accuracy atop the training data plots.
# Learning rate schedule. tf.keras.optimizers.schedules.ExponentialDecay()